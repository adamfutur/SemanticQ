{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ§  Anti-Graphiti: Semantic Data Augmentation with Ollama\n",
                "\n",
                "This notebook implements a **Data Augmentation Pipeline** to address the class imbalance in the Bloom's Taxonomy dataset. \n",
                "\n",
                "**Goal:** Generate high-quality, semantically rich questions for minority classes (`Apply`, `Analyze`, `Evaluate`, `Create`) using a local LLM (Ollama).\n",
                "\n",
                "**Strategy:**\n",
                "1.  **Analyze Imbalance**: Identify how many samples are needed for each class.\n",
                "2.  **Expert Prompting**: Use a \"Data Engineer\" persona with strict **5W1H** constraints.\n",
                "3.  **Semantic Filtering**: Use `spaCy` to ensure every generated question has a valid **Action Verb** as its ROOT.\n",
                "4.  **Merge**: Combine valid synthetic data with the original training set.\n",
                "\n",
                "> **Prerequisite**: Ensure Ollama is running (`ollama serve`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import time\n",
                "import random\n",
                "import requests\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from tqdm.auto import tqdm\n",
                "import spacy\n",
                "from collections import Counter\n",
                "\n",
                "# Configuration\n",
                "OLLAMA_URL = \"http://127.0.0.1:11434/api/generate\"\n",
                "MODEL_NAME = \"qwen3\" # Updated based on your screenshots\n",
                "DATA_PATH = \"../data/raw/bloom_questions.csv\"\n",
                "OUTPUT_PATH = \"../data/raw/bloom_questions_augmented.csv\"\n",
                "\n",
                "# Load SpaCy for Semantic Filtering\n",
                "try:\n",
                "    nlp = spacy.load(\"en_core_web_sm\")\n",
                "except:\n",
                "    print(\"Downloading SpaCy model...\")\n",
                "    os.system(\"python -m spacy download en_core_web_sm\")\n",
                "    nlp = spacy.load(\"en_core_web_sm\")\n",
                "\n",
                "print(f\"Target Model: {MODEL_NAME}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Distribution Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if os.path.exists(DATA_PATH):\n",
                "    df = pd.read_csv(DATA_PATH)\n",
                "    counts = df['level'].value_counts()\n",
                "    TARGET_COUNT = counts.max() # Aim to match the majority class\n",
                "    \n",
                "    print(f\"Majority Class: {counts.idxmax()} ({TARGET_COUNT} samples)\")\n",
                "    print(\"\\nSamples needed to balance:\")\n",
                "    needed = {}\n",
                "    for label, count in counts.items():\n",
                "        diff = TARGET_COUNT - count\n",
                "        if diff > 0:\n",
                "            needed[label] = diff\n",
                "            print(f\"  - {label}: +{diff}\")\n",
                "else:\n",
                "    print(\"Data file not found!\")\n",
                "    needed = {'Apply': 100, 'Analyze': 100} # Dummy defaults"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Ollama Integration (The Expert Persona)\n",
                "\n",
                "We use a specialized prompt to enforce:\n",
                "1.  **Linguistic Structure**: Strong Action Verb at the ROOT.\n",
                "2.  **Diversity**: Strict adherence to **5W1H** (Who, What, Where, When, Why, How).\n",
                "3.  **Context**: Educational domain."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_batch(level, count=5, model=MODEL_NAME):\n",
                "    \"\"\"Generate a batch of questions for a specific Bloom level.\"\"\"\n",
                "    \n",
                "    prompt = f\"\"\"\n",
                "    Role: You are an expert AI Data Engineer specializing in Bloom's Taxonomy.\n",
                "    Task: Generate {count} unique, high-quality educational questions for the Bloom's level: '{level}'.\n",
                "    \n",
                "    Constraints:\n",
                "    1. **5W1H Requirement**: You MUST vary the start of the questions. Use exactly this mix:\n",
                "       - 30% starting with 'How' (e.g., 'How would you...')\n",
                "       - 20% starting with 'Why' (e.g., 'Why does...')\n",
                "       - 20% starting with 'What' (e.g., 'What is the impact...')\n",
                "       - 30% Imperative/Direct commands (e.g., 'Design...', 'Critique...', 'Compare...')\n",
                "       \n",
                "    2. **Linguistic Structure**: Every question must have a main **Action Verb** that clearly maps to the '{level}' category.\n",
                "    \n",
                "    3. **Output Format**: Return ONLY a raw CSV list with no headers, no numbering, no preamble. Format: \"question\"\n",
                "    \"\"\"\n",
                "    \n",
                "    payload = {\n",
                "        \"model\": model,\n",
                "        \"prompt\": prompt,\n",
                "        \"stream\": False,\n",
                "        \"options\": {\n",
                "            \"temperature\": 0.85, # High creativity for diversity\n",
                "            \"top_p\": 0.9\n",
                "        }\n",
                "    }\n",
                "    \n",
                "    try:\n",
                "        response = requests.post(OLLAMA_URL, json=payload)\n",
                "        if response.status_code == 200:\n",
                "            res_json = response.json()\n",
                "            # Extract text and split by newlines\n",
                "            text = res_json.get('response', '')\n",
                "            # Basic cleanup\n",
                "            questions = [q.strip('\" \\t-1234567890.') for q in text.split('\\n') if len(q) > 10]\n",
                "            return questions\n",
                "        else:\n",
                "            print(f\"Error: {response.status_code}\")\n",
                "            return []\n",
                "    except Exception as e:\n",
                "        print(f\"Connection Error: {e}\")\n",
                "        return []\n",
                "\n",
                "# Test Connection\n",
                "print(\"Testing Ollama Connection...\")\n",
                "test_q = generate_batch(\"Apply\", count=1)\n",
                "print(f\"Result: {test_q}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Semantic Filtering (SemantiQ Core)\n",
                "\n",
                "We use **spaCy** to verify that the generated question actually looks like a question or a command. We check if the **ROOT** of the sentence is a verb (or satisfying specific POS tags)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def is_semantically_valid(question):\n",
                "    \"\"\"Check if the question has a valid linguistic structure.\"\"\"\n",
                "    doc = nlp(question)\n",
                "    \n",
                "    # 1. Length check\n",
                "    if len(doc) < 4:\n",
                "        return False\n",
                "        \n",
                "    # 2. ROOT Check: The root should usually be a VERB (Design, Explain) \n",
                "    # or the sentence should contain a Wh-word (Who, What, Where...)\n",
                "    has_verb_root = False\n",
                "    has_wh_word = False\n",
                "    \n",
                "    for token in doc:\n",
                "        if token.dep_ == 'ROOT' and token.pos_ in ['VERB', 'NOUN', 'PROPN']:\n",
                "            # Noun allowed because sometimes titles/definitions are parsed as nouns\n",
                "            has_verb_root = True\n",
                "        if token.tag_.startswith('W'): # Wh-determiner, Wh-pronoun, etc.\n",
                "            has_wh_word = True\n",
                "            \n",
                "    return has_verb_root or has_wh_word\n",
                "\n",
                "def filter_questions(questions):\n",
                "    valid = []\n",
                "    for q in questions:\n",
                "        if is_semantically_valid(q):\n",
                "            valid.append(q)\n",
                "    return valid"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Main Generation Loop\n",
                "\n",
                "We iterate through the classes that need augmentation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "generated_data = []\n",
                "\n",
                "for label, amount_needed in needed.items():\n",
                "    print(f\"\\nGenerating {amount_needed} samples for '{label}'...\")\n",
                "    \n",
                "    collected = 0\n",
                "    pbar = tqdm(total=amount_needed)\n",
                "    \n",
                "    while collected < amount_needed:\n",
                "        # Request a batch (ask for slightly more to account for filtering)\n",
                "        raw_batch = generate_batch(label, count=10)\n",
                "        if not raw_batch:\n",
                "            time.sleep(2) # Backoff if error\n",
                "            continue\n",
                "            \n",
                "        # Semantic Filter\n",
                "        valid_batch = filter_questions(raw_batch)\n",
                "        \n",
                "        # Add unique ones\n",
                "        for q in valid_batch:\n",
                "            if collected < amount_needed:\n",
                "                generated_data.append({'question': q, 'level': label})\n",
                "                collected += 1\n",
                "                pbar.update(1)\n",
                "    \n",
                "    pbar.close()\n",
                "    \n",
                "print(f\"\\nTotal Generated: {len(generated_data)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Export and Merge"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if generated_data:\n",
                "    df_aug = pd.DataFrame(generated_data)\n",
                "    \n",
                "    # Save Augmentation Only\n",
                "    df_aug.to_csv(\"../data/raw/generated_only.csv\", index=False)\n",
                "    \n",
                "    # Merge with Original\n",
                "    df_final = pd.concat([df, df_aug]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
                "    \n",
                "    df_final.to_csv(OUTPUT_PATH, index=False)\n",
                "    print(f\"\\nSaved Balanced Dataset to: {OUTPUT_PATH}\")\n",
                "    print(f\"Final Size: {len(df_final)}\")\n",
                "    print(df_final['level'].value_counts())\n",
                "else:\n",
                "    print(\"No data generated.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Bloom Env",
            "language": "python",
            "name": "bloom_env"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
